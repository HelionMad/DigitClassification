{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LENET START\n"
     ]
    }
   ],
   "source": [
    "print(\"LENET START\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-4:\n",
      "Traceback (most recent call last):\n",
      "Process Process-1:\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ryan/anaconda2/envs/deeplearning/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/home/ryan/anaconda2/envs/deeplearning/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/home/ryan/anaconda2/envs/deeplearning/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/home/ryan/anaconda2/envs/deeplearning/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/home/ryan/anaconda2/envs/deeplearning/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/ryan/anaconda2/envs/deeplearning/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/ryan/anaconda2/envs/deeplearning/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/ryan/anaconda2/envs/deeplearning/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ryan/anaconda2/envs/deeplearning/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ryan/anaconda2/envs/deeplearning/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "  File \"/home/ryan/anaconda2/envs/deeplearning/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "  File \"/home/ryan/anaconda2/envs/deeplearning/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "    r = index_queue.get()\n",
      "    r = index_queue.get()\n",
      "  File \"/home/ryan/anaconda2/envs/deeplearning/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "  File \"/home/ryan/anaconda2/envs/deeplearning/lib/python2.7/multiprocessing/queues.py\", line 374, in get\n",
      "  File \"/home/ryan/anaconda2/envs/deeplearning/lib/python2.7/multiprocessing/queues.py\", line 374, in get\n",
      "    r = index_queue.get()\n",
      "    racquire()\n",
      "    racquire()\n",
      "  File \"/home/ryan/anaconda2/envs/deeplearning/lib/python2.7/multiprocessing/queues.py\", line 374, in get\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "    return recv()\n",
      "  File \"/home/ryan/anaconda2/envs/deeplearning/lib/python2.7/site-packages/torch/multiprocessing/queue.py\", line 21, in recv\n",
      "    buf = self.recv_bytes()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-161769f8413e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m# backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ryan/anaconda2/envs/deeplearning/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ryan/anaconda2/envs/deeplearning/lib/python2.7/site-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "learning_rate = 1e-3\n",
    "batch_size = 2\n",
    "epoches = 50\n",
    "\n",
    "trans_img = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "trainset = MNIST('./data', train=True, transform=trans_img,download = True)\n",
    "testset = MNIST('./data', train=False, transform=trans_img,download = True)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# build network\n",
    "class Lenet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Lenet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(6, 16, 5, stride=1, padding=0),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(400, 120),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "lenet = Lenet()\n",
    "lenet.cuda()\n",
    "\n",
    "criterian = nn.CrossEntropyLoss(size_average=False)\n",
    "optimizer = optim.SGD(lenet.parameters(), lr=learning_rate)\n",
    "\n",
    "# train\n",
    "for i in range(epoches):\n",
    "    running_loss = 0.\n",
    "    running_acc = 0.\n",
    "    for (img, label) in trainloader:\n",
    "        img = Variable(img).cuda()\n",
    "        label = Variable(label).cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = lenet(img)\n",
    "        \n",
    "        loss = criterian(output, label)\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.data[0]\n",
    "        _, predict = torch.max(output, 1)\n",
    "        correct_num = (predict == label).sum()\n",
    "        running_acc += correct_num.data[0]\n",
    "\n",
    "    running_loss /= len(trainset)\n",
    "    running_acc /= len(trainset)\n",
    "\n",
    "    print(\"[%d/%d] Loss: %.5f, Acc: %.2f\" %(i+1, epoches, running_loss, 100*running_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss: 0.08437, Acc: 98.40 %\n"
     ]
    }
   ],
   "source": [
    "lenet.eval()\n",
    "\n",
    "testloss = 0.\n",
    "testacc = 0.\n",
    "for (img, label) in testloader:\n",
    "    img = Variable(img).cuda()\n",
    "    label = Variable(label).cuda()\n",
    "\n",
    "    output = lenet(img)\n",
    "    loss = criterian(output, label)\n",
    "    testloss += loss.data[0]\n",
    "    _, predict = torch.max(output, 1)\n",
    "    num_correct = (predict == label).sum()\n",
    "    testacc += num_correct.data[0]\n",
    "\n",
    "testloss /= len(testset)\n",
    "testacc /= len(testset)\n",
    "print(\"Test: Loss: %.5f, Acc: %.2f %%\" %(testloss, 100*testacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
